{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create a folder named data with file label_all.csv \n",
    "#  image.jpg as the sibling file\n",
    "#  models_grid.pkl as the sibling file\n",
    "\n",
    "image classes \n",
    "\n",
    "1- not very fresh\n",
    "2 - not fresh\n",
    "3 - fresh\n",
    "4 - very fresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78cdd7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prajj\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n",
      "C:\\Users\\prajj\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n",
      "C:\\Users\\prajj\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n",
      "C:\\Users\\prajj\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n",
      "C:\\Users\\prajj\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n",
      "C:\\Users\\prajj\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n",
      "C:\\Users\\prajj\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n",
      "C:\\Users\\prajj\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n",
      "C:\\Users\\prajj\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n",
      "C:\\Users\\prajj\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cluster\n",
    "\n",
    "#Setting directly\n",
    "# os.chdir(\"C:/Users/prajj/OneDrive/Desktop/capstoneserver/model/Predicting-sensory-evaluation-of-spinach-freshness-using-machine-learning-model-and-digital-images/Attached_file\")\n",
    "#Loading label\n",
    "df_label = pd.read_csv('data/label_all.csv', names=['label'])\n",
    "# Vector\n",
    "label = df_label.values\n",
    "label_all = label.flatten()\n",
    "#All data set\n",
    "N_img =1\n",
    "#Colum_Feature\n",
    "col_color=[]\n",
    "col_color.extend(['gry', 'b', 'g', 'r', 'h', 's', 'v', 'l', 'a', 'bl',\n",
    "                  'gry_std','b_std', 'g_std', 'r_std','h_std', 's_std', 'v_std','l_std','a_std','bl_std',\n",
    "                  'gry_min','b_min','g_min','r_min','h_min','s_min','v_min', 'l_min','a_min','bl_min'])\n",
    "feature_matrix_color = np.zeros((N_img,len(col_color)))\n",
    "feature_color = pd.DataFrame(feature_matrix_color, columns = col_color)\n",
    "for i in range(N_img):\n",
    "    filename = \"image.jpg\"\n",
    "    img = cv2.imread(filename)\n",
    "    img = cv2.resize(img, (int(np.round(img.shape[1]/5)), int(np.round(img.shape[0]/5))))\n",
    "    gry =cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #Otsu method\n",
    "    ret, img_thresh = cv2.threshold(gry, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    img_thresh = cv2.morphologyEx(img_thresh, cv2.MORPH_OPEN, kernel)\n",
    "    img_thresh = cv2.bitwise_not(img_thresh)\n",
    "    img_thresh = cv2.erode(img_thresh,kernel,iterations = 1)\n",
    "    height, width, color = img.shape \n",
    "    img_thresh3 = np.zeros((height, width, 3), dtype = \"uint8\")\n",
    "    img_thresh3[:,:,0], img_thresh3[:,:,1], img_thresh3[:,:,2] = img_thresh/255, img_thresh/255, img_thresh/255\n",
    "    #Remove Background \n",
    "    img_Hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    img_Lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    dst_gry = gry * (img_thresh/255)\n",
    "    dst_bgr = img * img_thresh3\n",
    "    dst_Hsv = img_Hsv * img_thresh3\n",
    "    dst_Lab = img_Lab * img_thresh3\n",
    "    \n",
    "    #Color feature extraction: gry,bgr,hsv,lab mean,std,min\n",
    "    feature_color['gry'][i] = dst_gry.T.flatten()[np.nonzero(dst_gry.T.flatten())].mean()\n",
    "    feature_color['b'][i] = dst_bgr.T[0].flatten()[np.nonzero(dst_bgr.T[0].flatten())].mean()\n",
    "    feature_color['g'][i] = dst_bgr.T[1].flatten()[np.nonzero(dst_bgr.T[1].flatten())].mean()\n",
    "    feature_color['r'][i] = dst_bgr.T[2].flatten()[np.nonzero(dst_bgr.T[2].flatten())].mean()\n",
    "    feature_color['h'][i] = dst_Hsv.T[0].flatten()[np.nonzero(dst_Hsv.T[0].flatten())].mean()\n",
    "    feature_color['s'][i] = dst_Hsv.T[1].flatten()[np.nonzero(dst_Hsv.T[1].flatten())].mean()\n",
    "    feature_color['v'][i] = dst_Hsv.T[2].flatten()[np.nonzero(dst_Hsv.T[2].flatten())].mean()\n",
    "    feature_color['l'][i] = dst_Lab.T[0].flatten()[np.nonzero(dst_Lab.T[0].flatten())].mean()\n",
    "    feature_color['a'][i] = dst_Lab.T[1].flatten()[np.nonzero(dst_Lab.T[1].flatten())].mean()\n",
    "    feature_color['bl'][i] = dst_Lab.T[2].flatten()[np.nonzero(dst_Lab.T[2].flatten())].mean()\n",
    "    feature_color['gry_std'][i] = dst_gry.T.flatten()[np.nonzero(dst_gry.T.flatten())].std()\n",
    "    feature_color['b_std'][i] = dst_bgr.T[0].flatten()[np.nonzero(dst_bgr.T[0].flatten())].std()\n",
    "    feature_color['g_std'][i] = dst_bgr.T[1].flatten()[np.nonzero(dst_bgr.T[1].flatten())].std()\n",
    "    feature_color['r_std'][i] = dst_bgr.T[2].flatten()[np.nonzero(dst_bgr.T[2].flatten())].std()\n",
    "    feature_color['h_std'][i] = dst_Hsv.T[0].flatten()[np.nonzero(dst_Hsv.T[0].flatten())].std()\n",
    "    feature_color['s_std'][i] =  dst_Hsv.T[1].flatten()[np.nonzero(dst_Hsv.T[1].flatten())].std()\n",
    "    feature_color['v_std'][i] = dst_Hsv.T[2].flatten()[np.nonzero(dst_Hsv.T[2].flatten())].std()\n",
    "    feature_color['l_std'][i] = dst_Lab.T[0].flatten()[np.nonzero(dst_Lab.T[0].flatten())].std()\n",
    "    feature_color['a_std'][i] = dst_Lab.T[1].flatten()[np.nonzero(dst_Lab.T[1].flatten())].std()\n",
    "    feature_color['bl_std'][i] = dst_Lab.T[2].flatten()[np.nonzero(dst_Lab.T[2].flatten())].std()\n",
    "    feature_color['gry_min'][i] = dst_gry.T.flatten()[np.nonzero(dst_gry.T.flatten())].min()\n",
    "    feature_color['b_min'][i] = dst_bgr.T[0].flatten()[np.nonzero(dst_bgr.T[0].flatten())].min()\n",
    "    feature_color['g_min'][i] = dst_bgr.T[1].flatten()[np.nonzero(dst_bgr.T[1].flatten())].min()\n",
    "    feature_color['r_min'][i] = dst_bgr.T[2].flatten()[np.nonzero(dst_bgr.T[2].flatten())].min()\n",
    "    feature_color['h_min'][i] = dst_Hsv.T[0].flatten()[np.nonzero(dst_Hsv.T[0].flatten())].min()\n",
    "    feature_color['s_min'][i] = dst_Hsv.T[1].flatten()[np.nonzero(dst_Hsv.T[1].flatten())].min()\n",
    "    feature_color['v_min'][i] = dst_Hsv.T[2].flatten()[np.nonzero(dst_Hsv.T[2].flatten())].min()\n",
    "    feature_color['l_min'][i] = dst_Lab.T[0].flatten()[np.nonzero(dst_Lab.T[0].flatten())].min()\n",
    "    feature_color['a_min'][i] = dst_Lab.T[1].flatten()[np.nonzero(dst_Lab.T[1].flatten())].min()\n",
    "    feature_color['bl_min'][i] = dst_Lab.T[2].flatten()[np.nonzero(dst_Lab.T[2].flatten())].min()\n",
    "\n",
    "#label_color_fearue\n",
    "df_att = pd.concat([df_label[:N_img],feature_color],axis=1)\n",
    "#Save the label and color information\n",
    "df_att.to_csv('data/color_features_dummy.csv')\n",
    "#Load the label and color information\n",
    "df = pd.read_csv('data/color_features_dummy.csv', index_col=0)\n",
    "#Seperating the dataset as response variable and feature variabes\n",
    "X = df.drop(['label'],axis=1)\n",
    "y = df['label']\n",
    "#Preparing for local feature by Orb\n",
    "#Train and Test splitting of data \n",
    "X_train=X\n",
    "y_train=y\n",
    "index_train = X_train.index\n",
    "#Preparing_for_local_feature_detection\n",
    "orb = cv2.ORB_create()\n",
    "features_orb = []\n",
    "features_orb_bgr = [[],[],[]]\n",
    "features_orb_Lab = [[], [], []]\n",
    "features_orb_hsv = [[], [], []]\n",
    "for i in index_train:\n",
    "    filename = \"image.jpg\"\n",
    "    img = cv2.imread(filename)\n",
    "    img = cv2.resize(img, (int(np.round(img.shape[1]/5)), int(np.round(img.shape[0]/5))))\n",
    "    gry =cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, img_thresh = cv2.threshold(gry, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    img_thresh = cv2.morphologyEx(img_thresh, cv2.MORPH_OPEN, kernel)\n",
    "    img_thresh = cv2.bitwise_not(img_thresh)\n",
    "    img_thresh = cv2.erode(img_thresh,kernel,iterations = 1)\n",
    "    height, width, color = img.shape         \n",
    "    img_thresh3 = np.zeros((height, width, 3), dtype = \"uint8\")\n",
    "    img_thresh3[:,:,0], img_thresh3[:,:,1], img_thresh3[:,:,2] = img_thresh/255, img_thresh/255, img_thresh/255\n",
    "    img_Lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    img_Hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    dst_bgr = img * img_thresh3\n",
    "    dst_Lab = img_Lab * img_thresh3\n",
    "    dst_Hsv = img_Hsv * img_thresh3\n",
    "    try:\n",
    "        features_orb.extend(orb.detectAndCompute(gry, None)[1])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for z in range(3):\n",
    "        try:\n",
    "            features_orb_bgr[z].extend(orb.detectAndCompute(dst_bgr[:,:,z], None)[1])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            features_orb_Lab[z].extend(orb.detectAndCompute(dst_Lab[:,:,z], None)[1])\n",
    "        except:\n",
    "            pass    \n",
    "        try:\n",
    "            features_orb_hsv[z].extend(orb.detectAndCompute(dst_Hsv[:,:,z], None)[1])\n",
    "        except:\n",
    "            pass    \n",
    "#Making bag of features\n",
    "c_n = 20\n",
    "visual_words_orb_bgr = [[],[],[]]\n",
    "visual_words_orb_Lab = [[],[],[]]\n",
    "visual_words_orb_hsv = [[],[],[]]\n",
    "visual_words_orb = cluster.MiniBatchKMeans(n_clusters=c_n,random_state=25).fit(features_orb).cluster_centers_\n",
    "for z in range(3):\n",
    "    visual_words_orb_bgr[z] = cluster.MiniBatchKMeans(n_clusters=c_n,random_state=25).fit(features_orb_bgr[z]).cluster_centers_\n",
    "    visual_words_orb_Lab[z] = cluster.MiniBatchKMeans(n_clusters=c_n,random_state=25).fit(features_orb_Lab[z]).cluster_centers_\n",
    "    visual_words_orb_hsv[z] = cluster.MiniBatchKMeans(n_clusters=c_n,random_state=25).fit(features_orb_hsv[z]).cluster_centers_\n",
    "\n",
    "#Training\n",
    "#Vector of visual word index for training data set\n",
    "Vector_orb_gry = np.zeros([len(index_train),c_n])\n",
    "Vector_orb_bgr = [np.zeros([len(index_train),c_n]),np.zeros([len(index_train),c_n]),np.zeros([len(index_train),c_n])]\n",
    "Vector_orb_Lab = [np.zeros([len(index_train),c_n]),np.zeros([len(index_train),c_n]),np.zeros([len(index_train),c_n])]\n",
    "Vector_orb_hsv = [np.zeros([len(index_train),c_n]),np.zeros([len(index_train),c_n]),np.zeros([len(index_train),c_n])]\n",
    "for i, I  in zip(range(len(index_train)),index_train):\n",
    "    filename = \"image.jpg\"\n",
    "    img = cv2.imread(filename)\n",
    "    img = cv2.resize(img, (int(np.round(img.shape[1]/5)), int(np.round(img.shape[0]/5))))\n",
    "    gry =cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, img_thresh = cv2.threshold(gry, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    img_thresh = cv2.morphologyEx(img_thresh, cv2.MORPH_OPEN, kernel)\n",
    "    img_thresh = cv2.bitwise_not(img_thresh)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    img_thresh = cv2.erode(img_thresh,kernel,iterations = 1)\n",
    "    height, width, color = img.shape \n",
    "    dst_bgr = np.zeros((height, width, 3), dtype = \"uint8\")             \n",
    "    img_thresh3 = np.zeros((height, width, 3), dtype = \"uint8\")\n",
    "    img_thresh3[:,:,0], img_thresh3[:,:,1], img_thresh3[:,:,2] = img_thresh/255, img_thresh/255, img_thresh/255\n",
    "    img_Lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    img_Hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    dst_bgr = img * img_thresh3\n",
    "    dst_Hsv = img_Hsv * img_thresh3\n",
    "    dst_Lab = img_Lab * img_thresh3\n",
    "    \n",
    "    #orb gry\n",
    "    features_orb = orb.detectAndCompute(gry, None)[1]\n",
    "    vector_orb = np.zeros(c_n)\n",
    "    try:\n",
    "        for f in features_orb:\n",
    "            vector_orb[((visual_words_orb - f)**2).sum(axis=1).argmin()] += 1\n",
    "    except:\n",
    "            pass\n",
    "    Vector_orb_gry[i,:] = vector_orb\n",
    "    #Orb color\n",
    "    for z in range(3):\n",
    "        #orb bgr\n",
    "        features_orb = orb.detectAndCompute(dst_bgr[:,:,z], None)[1]\n",
    "        vector_orb = np.zeros(c_n)\n",
    "        try:\n",
    "            for f in features_orb:\n",
    "                vector_orb[((visual_words_orb_bgr[z] - f)**2).sum(axis=1).argmin()] += 1\n",
    "        except:\n",
    "                pass\n",
    "        Vector_orb_bgr[z][i,:] = vector_orb\n",
    "        \n",
    "        #orb Lab\n",
    "        features_orb = orb.detectAndCompute(dst_Lab[:,:,z], None)[1]\n",
    "        vector_orb = np.zeros(c_n)\n",
    "        try:\n",
    "            for f in features_orb:\n",
    "                vector_orb[((visual_words_orb_Lab[z] - f)**2).sum(axis=1).argmin()] += 1\n",
    "        except:\n",
    "                pass\n",
    "        Vector_orb_Lab[z][i,:] = vector_orb\n",
    "        \n",
    "        #orb hsv\n",
    "        features_orb = orb.detectAndCompute(dst_Hsv[:,:,z], None)[1]\n",
    "        vector_orb = np.zeros(c_n)\n",
    "        try:\n",
    "            for f in features_orb:\n",
    "                vector_orb[((visual_words_orb_hsv[z] - f)**2).sum(axis=1).argmin()] += 1\n",
    "        except:\n",
    "                pass\n",
    "        Vector_orb_hsv[z][i,:] = vector_orb\n",
    "    #############################################################\n",
    "#Colum names bag of features by Orb\n",
    "n_orb_gry, n_orb_l, n_orb_a, n_orb_bl, n_orb_h, n_orb_s, n_orb_v = ['orb_gry']*c_n, ['orb_l']*c_n, ['orb_a']*c_n, ['orb_bl']*c_n,['orb_h']*c_n, ['orb_s']*c_n, ['orb_v']*c_n\n",
    "n_orb_b, n_orb_g, n_orb_r = ['orb_b']*c_n, ['orb_g']*c_n, ['orb_r']*c_n\n",
    "\n",
    "number = list(range(1,c_n+1))\n",
    "number_list = list(map(str, number))\n",
    "orb_gry_list = [a + b for a, b in zip(n_orb_gry, number_list)]\n",
    "orb_b_list = [a + b for a, b in zip(n_orb_b, number_list)]\n",
    "orb_g_list = [a + b for a, b in zip(n_orb_g, number_list)]\n",
    "orb_r_list = [a + b for a, b in zip(n_orb_r, number_list)]\n",
    "orb_l_list = [a + b for a, b in zip(n_orb_l, number_list)]\n",
    "orb_a_list = [a + b for a, b in zip(n_orb_a, number_list)]\n",
    "orb_bl_list = [a + b for a, b in zip(n_orb_bl, number_list)]\n",
    "orb_h_list = [a + b for a, b in zip(n_orb_h, number_list)]\n",
    "orb_s_list = [a + b for a, b in zip(n_orb_s, number_list)]\n",
    "orb_v_list = [a + b for a, b in zip(n_orb_v, number_list)]\n",
    "feature_orb_gry = pd.DataFrame(Vector_orb_gry, columns = orb_gry_list)\n",
    "feature_orb_b = pd.DataFrame(Vector_orb_bgr[0], columns = orb_b_list)\n",
    "feature_orb_g = pd.DataFrame(Vector_orb_bgr[1], columns = orb_g_list)\n",
    "feature_orb_r = pd.DataFrame(Vector_orb_bgr[2], columns = orb_r_list)\n",
    "feature_orb_L = pd.DataFrame(Vector_orb_Lab[0], columns = orb_l_list)\n",
    "feature_orb_a = pd.DataFrame(Vector_orb_Lab[1], columns = orb_a_list)\n",
    "feature_orb_bl = pd.DataFrame(Vector_orb_Lab[2], columns = orb_bl_list)\n",
    "feature_orb_h = pd.DataFrame(Vector_orb_hsv[0], columns = orb_h_list)\n",
    "feature_orb_s = pd.DataFrame(Vector_orb_hsv[1], columns = orb_s_list)\n",
    "feature_orb_v = pd.DataFrame(Vector_orb_hsv[2], columns = orb_v_list)\n",
    "\n",
    "col=[]\n",
    "col.extend(orb_gry_list + orb_b_list + orb_g_list + orb_r_list + orb_l_list + orb_a_list + orb_bl_list + orb_h_list + orb_s_list + orb_v_list)\n",
    "df_train = pd.concat([pd.DataFrame(y_train.values, columns=['label']),pd.DataFrame(X_train.values, columns=df.columns[1:]),\n",
    "                      feature_orb_gry, feature_orb_b, feature_orb_g, feature_orb_r, feature_orb_L, feature_orb_a, feature_orb_bl, feature_orb_h, feature_orb_s, feature_orb_v],axis=1)\n",
    "\n",
    "\n",
    "df_train_unlabel = df_train.drop('label', axis=1)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train_unlabel)\n",
    "scale_train =scaler.transform(df_train_unlabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4adef362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>gry</th>\n",
       "      <th>b</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>h</th>\n",
       "      <th>s</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>a</th>\n",
       "      <th>...</th>\n",
       "      <th>gry_min</th>\n",
       "      <th>b_min</th>\n",
       "      <th>g_min</th>\n",
       "      <th>r_min</th>\n",
       "      <th>h_min</th>\n",
       "      <th>s_min</th>\n",
       "      <th>v_min</th>\n",
       "      <th>l_min</th>\n",
       "      <th>a_min</th>\n",
       "      <th>bl_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>77.660581</td>\n",
       "      <td>30.857381</td>\n",
       "      <td>94.180801</td>\n",
       "      <td>63.059652</td>\n",
       "      <td>44.864168</td>\n",
       "      <td>172.803123</td>\n",
       "      <td>94.278079</td>\n",
       "      <td>92.61482</td>\n",
       "      <td>104.996656</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        gry          b          g          r          h           s  \\\n",
       "0      3  77.660581  30.857381  94.180801  63.059652  44.864168  172.803123   \n",
       "\n",
       "           v         l           a  ...  gry_min  b_min  g_min  r_min  h_min  \\\n",
       "0  94.278079  92.61482  104.996656  ...     29.0    1.0   40.0   18.0   19.0   \n",
       "\n",
       "   s_min  v_min  l_min  a_min  bl_min  \n",
       "0   51.0   40.0   35.0   95.0   141.0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7ca306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_unlabel = df_train.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a75ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gry</th>\n",
       "      <th>b</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>h</th>\n",
       "      <th>s</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>a</th>\n",
       "      <th>bl</th>\n",
       "      <th>...</th>\n",
       "      <th>orb_v11</th>\n",
       "      <th>orb_v12</th>\n",
       "      <th>orb_v13</th>\n",
       "      <th>orb_v14</th>\n",
       "      <th>orb_v15</th>\n",
       "      <th>orb_v16</th>\n",
       "      <th>orb_v17</th>\n",
       "      <th>orb_v18</th>\n",
       "      <th>orb_v19</th>\n",
       "      <th>orb_v20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.660581</td>\n",
       "      <td>30.857381</td>\n",
       "      <td>94.180801</td>\n",
       "      <td>63.059652</td>\n",
       "      <td>44.864168</td>\n",
       "      <td>172.803123</td>\n",
       "      <td>94.278079</td>\n",
       "      <td>92.61482</td>\n",
       "      <td>104.996656</td>\n",
       "      <td>159.581385</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gry          b          g          r          h           s  \\\n",
       "0  77.660581  30.857381  94.180801  63.059652  44.864168  172.803123   \n",
       "\n",
       "           v         l           a          bl  ...  orb_v11  orb_v12  \\\n",
       "0  94.278079  92.61482  104.996656  159.581385  ...     33.0      4.0   \n",
       "\n",
       "   orb_v13  orb_v14  orb_v15  orb_v16  orb_v17  orb_v18  orb_v19  orb_v20  \n",
       "0      4.0     19.0      5.0     33.0      2.0     31.0     30.0     12.0  \n",
       "\n",
       "[1 rows x 230 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_unlabel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3dace83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "loaded_model = joblib.load('models_grid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92531ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train_unlabel)\n",
    "scale_train =scaler.transform(df_train_unlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2252d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(scale_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17804e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall numpy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
