{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fab5459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836 209 836 209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prajj\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:72: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "C:\\Users\\prajj\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "10/10 [==============================] - 2s 6ms/step - loss: 0.8657 - accuracy: 0.2297\n",
      "Epoch 2/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7347 - accuracy: 0.5167\n",
      "Epoch 3/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6398 - accuracy: 0.4581\n",
      "Epoch 4/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5763 - accuracy: 0.5060\n",
      "Epoch 5/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.5383\n",
      "Epoch 6/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.6100\n",
      "Epoch 7/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.6172\n",
      "Epoch 8/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.6328\n",
      "Epoch 9/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.6411\n",
      "Epoch 10/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.7261\n",
      "Epoch 11/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.6507\n",
      "Epoch 12/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3109 - accuracy: 0.7309\n",
      "Epoch 13/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2770 - accuracy: 0.7404\n",
      "Epoch 14/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.7644\n",
      "Epoch 15/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.7835\n",
      "Epoch 16/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2408 - accuracy: 0.7967\n",
      "Epoch 17/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 0.7967\n",
      "Epoch 18/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2263 - accuracy: 0.8086\n",
      "Epoch 19/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2011 - accuracy: 0.8194\n",
      "Epoch 20/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2060 - accuracy: 0.8254\n",
      "Epoch 21/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1738 - accuracy: 0.8493\n",
      "Epoch 22/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1658 - accuracy: 0.8624\n",
      "Epoch 23/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1697 - accuracy: 0.8565\n",
      "Epoch 24/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1730 - accuracy: 0.8541\n",
      "Epoch 25/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1529 - accuracy: 0.8744\n",
      "Epoch 26/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1341 - accuracy: 0.8852\n",
      "Epoch 27/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.8840\n",
      "Epoch 28/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1227 - accuracy: 0.9043\n",
      "Epoch 29/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1520 - accuracy: 0.8911\n",
      "Epoch 30/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1647 - accuracy: 0.9043\n",
      "Epoch 31/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1330 - accuracy: 0.9091\n",
      "Epoch 32/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9163\n",
      "Epoch 33/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9294\n",
      "Epoch 34/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0940 - accuracy: 0.9211\n",
      "Epoch 35/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9282\n",
      "Epoch 36/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9342\n",
      "Epoch 37/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9306\n",
      "Epoch 38/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.9258\n",
      "Epoch 39/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9510\n",
      "Epoch 40/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0850 - accuracy: 0.9378\n",
      "Epoch 41/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9486\n",
      "Epoch 42/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0769 - accuracy: 0.9414\n",
      "Epoch 43/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9510\n",
      "Epoch 44/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9498\n",
      "Epoch 45/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9569\n",
      "Epoch 46/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.9438\n",
      "Epoch 47/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.9533\n",
      "Epoch 48/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0651 - accuracy: 0.9569\n",
      "Epoch 49/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9641\n",
      "Epoch 50/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.9438\n",
      "Epoch 51/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9533\n",
      "Epoch 52/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9641\n",
      "Epoch 53/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9474\n",
      "Epoch 54/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9605\n",
      "Epoch 55/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9605\n",
      "Epoch 56/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9677\n",
      "Epoch 57/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9581\n",
      "Epoch 58/120\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.9665\n",
      "Epoch 59/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9653\n",
      "Epoch 60/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9653\n",
      "Epoch 61/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9629\n",
      "Epoch 62/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9725\n",
      "Epoch 63/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9701\n",
      "Epoch 64/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9677\n",
      "Epoch 65/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9749\n",
      "Epoch 66/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9665\n",
      "Epoch 67/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9761\n",
      "Epoch 68/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9797\n",
      "Epoch 69/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9785\n",
      "Epoch 70/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9713\n",
      "Epoch 71/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9653\n",
      "Epoch 72/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9761\n",
      "Epoch 73/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9689\n",
      "Epoch 74/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9749\n",
      "Epoch 75/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9737\n",
      "Epoch 76/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9713\n",
      "Epoch 77/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9761\n",
      "Epoch 78/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9880\n",
      "Epoch 79/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9797\n",
      "Epoch 80/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9785\n",
      "Epoch 81/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.9773\n",
      "Epoch 82/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9773\n",
      "Epoch 83/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9809\n",
      "Epoch 84/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 0.9773\n",
      "Epoch 85/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9761\n",
      "Epoch 86/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.9677\n",
      "Epoch 87/120\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0434 - accuracy: 0.9629\n",
      "Epoch 88/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9761\n",
      "Epoch 89/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9713\n",
      "Epoch 90/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9821\n",
      "Epoch 91/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9773\n",
      "Epoch 92/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9725\n",
      "Epoch 93/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9868\n",
      "Epoch 94/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9785\n",
      "Epoch 95/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9856\n",
      "Epoch 96/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9821\n",
      "Epoch 97/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9761\n",
      "Epoch 98/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9725\n",
      "Epoch 99/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9833\n",
      "Epoch 100/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9833\n",
      "Epoch 101/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9868\n",
      "Epoch 102/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9797\n",
      "Epoch 103/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9809\n",
      "Epoch 104/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9856\n",
      "Epoch 105/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9797\n",
      "Epoch 106/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9797\n",
      "Epoch 107/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 0.9904\n",
      "Epoch 108/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9785\n",
      "Epoch 109/120\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9833\n",
      "Epoch 110/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9856\n",
      "Epoch 111/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9856\n",
      "Epoch 112/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9868\n",
      "Epoch 113/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9904\n",
      "Epoch 114/120\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9880\n",
      "Epoch 115/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9833\n",
      "Epoch 116/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.9809\n",
      "Epoch 117/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9844\n",
      "Epoch 118/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9844\n",
      "Epoch 119/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9785\n",
      "Epoch 120/120\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9880\n",
      "Best: 0.69% using {'activation': 'relu', 'batch_size': 90, 'dropout_rate': 0.1, 'epochs': 120, 'learn_rate': 0.001}\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "\n",
      "val_acc: 69.25%\n",
      "train_score: 1.00\n",
      "test_score: 0.64\n",
      "train_cm:\n",
      " [[138   0   0   0]\n",
      " [  0 298   0   0]\n",
      " [  0   0 362   0]\n",
      " [  0   0   0  38]]\n",
      "test_cm:\n",
      " [[26  8  0  0]\n",
      " [12 47 15  1]\n",
      " [ 0 22 60  8]\n",
      " [ 0  0  9  1]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#Random seeds\n",
    "import random as rn\n",
    "def seed_everything(seed=12):\n",
    "    rn.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tensorflow.random.set_seed(seed)\n",
    "    session_conf = tensorflow.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1\n",
    "    )\n",
    "    sess = tensorflow.compat.v1.Session(graph=tensorflow.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tensorflow.compat.v1.keras.backend.set_session(sess)\n",
    "seed_everything(12)\n",
    "\n",
    "#Setting directly\n",
    "os.chdir(\"C:/Users/prajj/OneDrive/Desktop/capstoneserver/model/Predicting-sensory-evaluation-of-spinach-freshness-using-machine-learning-model-and-digital-images/Attached_file\")\n",
    "df = pd.read_csv('data/train_feature.csv', index_col=0)\n",
    "X_train = df.drop(['label'],axis=1)\n",
    "y_train = df['label'].astype(int)\n",
    "df = pd.read_csv('data/test_feature.csv', index_col=0)\n",
    "X_test = df.drop(['label'],axis=1)\n",
    "y_test = df['label'].astype(int)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\n",
    "#Scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scale_train =scaler.transform(X_train)\n",
    "scale_test =scaler.transform(X_test)\n",
    "\n",
    "#Class name\n",
    "y_train_ca =y_train-1\n",
    "y_train_ca =to_categorical(y_train_ca, num_classes=4)\n",
    "y_test_ca = y_test-1\n",
    "#Import collections\n",
    "class_weight ={0:1, 1:0.46, 2:0.38, 3:3.6}\n",
    "model = Sequential()\n",
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(learn_rate=0.01,activation='relu',dropout_rate=0.1):\n",
    "#Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=X_test.shape[1], activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    # Compile model\n",
    "    optimizer = Adam(lr=learn_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "#Create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "#Define the grid search parameters\n",
    "batch_size = [30, 60, 90, 120]\n",
    "epochs = [60, 80, 120, 150]\n",
    "learn_rate = [0.001]\n",
    "dropout_rate = [0.1]\n",
    "activation = ['sigmoid','relu']\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs,learn_rate=learn_rate, activation=activation, dropout_rate=dropout_rate)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid ,n_jobs=-1, cv=5)\n",
    "grid_result = grid.fit(scale_train, y_train_ca, verbose=1, class_weight=class_weight)\n",
    "#Summarize results\n",
    "print(\"Best: %.2f%% using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "y_pred_train = grid_result.predict(scale_train)\n",
    "y_pred_test = grid_result.predict(scale_test)  \n",
    "train_score = accuracy_score(y_train.values-1,y_pred_train)\n",
    "test_score = accuracy_score(y_test.values-1,y_pred_test)\n",
    "print(\"\\n%s: %.2f%%\" % ('val_acc', grid_result.best_score_*100))\n",
    "print('train_score: '+str(\"{0:.2f}\".format(train_score)))\n",
    "print('test_score: '+str(\"{0:.2f}\".format(test_score)))\n",
    "print(\"train_cm:\\n\", confusion_matrix(y_train.values-1, y_pred_train))\n",
    "print(\"test_cm:\\n\", confusion_matrix(y_test.values-1, y_pred_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53efe8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e7aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Assuming you have a trained model 'model'\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccdc4a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jolib\n",
      "  Downloading joLib-0.0.1-py3-none-any.whl (1.2 kB)\n",
      "Installing collected packages: jolib\n",
      "Successfully installed jolib-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e6580a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://35e776df-1623-462c-ae63-b940eb396aaf/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_file_name.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "#save your model or results\n",
    "joblib.load(gri 'model_file_name.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8334b82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836 209 836 209\n",
      "svc_rbf has been fitted.\n",
      "Cross validation 0.71\n",
      "Acc train: 1.00\n",
      "Normalized cm train:\n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "svc_rbf\n",
      "-----------\n",
      "Acc test: 0.68\n",
      "Normalized cm test:\n",
      " [[0.55882353 0.41176471 0.02941176 0.        ]\n",
      " [0.04       0.73333333 0.22666667 0.        ]\n",
      " [0.         0.24444444 0.75555556 0.        ]\n",
      " [0.         0.         0.9        0.1       ]]\n",
      "Best Hyper Parameters:\n",
      " {'svc__C': 3, 'svc__gamma': 0.01, 'svc__kernel': 'rbf', 'svc__random_state': 12}\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages.\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Setting directly\n",
    "os.chdir(\"C:/Users/prajj/OneDrive/Desktop/capstoneserver/model/Predicting-sensory-evaluation-of-spinach-freshness-using-machine-learning-model-and-digital-images/Attached_file\")\n",
    "\n",
    "#Loading training and test dataset\n",
    "df = pd.read_csv('data/train_feature.csv', index_col=0)\n",
    "X_train = df.drop(['label'],axis=1)\n",
    "y_train = df['label'].astype(int)\n",
    "df = pd.read_csv('data/test_feature.csv', index_col=0)\n",
    "X_test = df.drop(['label'],axis=1)\n",
    "y_test = df['label'].astype(int)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\n",
    "#Scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scale_train =scaler.transform(X_train)\n",
    "scale_test =scaler.transform(X_test)\n",
    "#pipelines\n",
    "pipelines = {\n",
    "        \"svc_rbf\": make_pipeline(SVC(class_weight='balanced',random_state=12))\n",
    "}\n",
    "svc_rbf_hyperparameters = {\n",
    "    'svc__kernel': ['rbf'],\n",
    "    'svc__C': np.arange(1,10,1),\n",
    "    'svc__gamma':np.logspace(-4, 0, 5, base=10),\n",
    "    \"svc__random_state\":[12]\n",
    "}\n",
    "hyperparameters = {\n",
    "        \"svc_rbf\":svc_rbf_hyperparameters\n",
    "}\n",
    "\n",
    "# Create empty dictionary called fitted_models\n",
    "fitted_models = {}\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    # Create cross-validation object from pipeline and hyperparameters\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv= 5, n_jobs= -1,scoring='accuracy')    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(scale_train, y_train)    \n",
    "    # Store model in fitted_models[name] \n",
    "    fitted_models[name] = model    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted.')\n",
    "op=''    \n",
    "for name, model in fitted_models.items():\n",
    "    op=model\n",
    "    print(\"Cross validation\", \"{0:.2f}\".format(model.best_score_))\n",
    "    pred = model.predict(scale_train)\n",
    "    C = confusion_matrix(y_train, pred)\n",
    "    print('Acc train:', \"{0:.2f}\".format(accuracy_score(y_train, pred)))\n",
    "    print(\"Normalized cm train:\\n\", C.astype('float') / C.sum(axis=1)[:, np.newaxis])\n",
    "for name, model in fitted_models.items():\n",
    "    print(name)\n",
    "    print(\"-----------\")\n",
    "    pred = model.predict(scale_test)\n",
    "    C = confusion_matrix(y_test, pred)\n",
    "    print('Acc test:', \"{0:.2f}\".format(accuracy_score(y_test, pred)))\n",
    "    print(\"Normalized cm test:\\n\", C.astype('float') / C.sum(axis=1)[:, np.newaxis])\n",
    "    print(\"Best Hyper Parameters:\\n\",model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d2567a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      4\n",
       "2      1\n",
       "3      2\n",
       "4      1\n",
       "      ..\n",
       "204    2\n",
       "205    3\n",
       "206    3\n",
       "207    3\n",
       "208    3\n",
       "Name: label, Length: 209, dtype: int32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1ee15c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('svc',\n",
       "                                        SVC(class_weight='balanced',\n",
       "                                            random_state=12))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'svc__C': array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                         'svc__gamma': array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00]),\n",
       "                         'svc__kernel': ['rbf'], 'svc__random_state': [12]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "gs=fitted_models['svc_rbf']\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "509b0555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7400be8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models_grid.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(fitted, 'models_grid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7a8f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row=X_train.iloc[0]\n",
    "a=np.array(first_row)\n",
    "a=a.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2733557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('models_grid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16f2375d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, 2, 1, 3, 3, 1, 1, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 2, 2, 2,\n",
       "       2, 1, 2, 2, 3, 1, 3, 2, 2, 2, 3, 2, 1, 3, 3, 3, 3, 2, 2, 2, 3, 2,\n",
       "       3, 1, 2, 2, 2, 2, 1, 2, 2, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3,\n",
       "       2, 3, 3, 3, 3, 2, 3, 2, 1, 2, 3, 3, 3, 2, 3, 1, 3, 1, 2, 1, 2, 3,\n",
       "       3, 3, 2, 2, 3, 2, 2, 3, 3, 2, 1, 2, 3, 2, 2, 2, 3, 1, 2, 2, 2, 3,\n",
       "       3, 3, 2, 2, 3, 3, 3, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "       2, 2, 3, 3, 3, 3, 2, 3, 2, 3, 1, 2, 2, 1, 3, 2, 2, 2, 2, 3, 3, 3,\n",
       "       3, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 3, 1, 3, 3, 2, 2, 1, 3, 3, 1, 3,\n",
       "       3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 3, 3, 3, 3, 2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(scale_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b98d74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gry</th>\n",
       "      <th>b</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>h</th>\n",
       "      <th>s</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>a</th>\n",
       "      <th>bl</th>\n",
       "      <th>...</th>\n",
       "      <th>orb_v11</th>\n",
       "      <th>orb_v12</th>\n",
       "      <th>orb_v13</th>\n",
       "      <th>orb_v14</th>\n",
       "      <th>orb_v15</th>\n",
       "      <th>orb_v16</th>\n",
       "      <th>orb_v17</th>\n",
       "      <th>orb_v18</th>\n",
       "      <th>orb_v19</th>\n",
       "      <th>orb_v20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.279621</td>\n",
       "      <td>34.183760</td>\n",
       "      <td>94.398857</td>\n",
       "      <td>70.153900</td>\n",
       "      <td>42.267678</td>\n",
       "      <td>165.889913</td>\n",
       "      <td>94.401796</td>\n",
       "      <td>94.009250</td>\n",
       "      <td>108.220617</td>\n",
       "      <td>158.627226</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.393634</td>\n",
       "      <td>39.465580</td>\n",
       "      <td>89.203236</td>\n",
       "      <td>68.729331</td>\n",
       "      <td>42.560133</td>\n",
       "      <td>143.786610</td>\n",
       "      <td>89.224835</td>\n",
       "      <td>89.600067</td>\n",
       "      <td>110.960220</td>\n",
       "      <td>153.843064</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.039218</td>\n",
       "      <td>39.302562</td>\n",
       "      <td>95.349459</td>\n",
       "      <td>72.226219</td>\n",
       "      <td>42.612996</td>\n",
       "      <td>151.611681</td>\n",
       "      <td>95.349459</td>\n",
       "      <td>95.417023</td>\n",
       "      <td>109.145027</td>\n",
       "      <td>156.659661</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.438145</td>\n",
       "      <td>38.150518</td>\n",
       "      <td>77.346432</td>\n",
       "      <td>59.177782</td>\n",
       "      <td>44.345727</td>\n",
       "      <td>129.958599</td>\n",
       "      <td>77.348153</td>\n",
       "      <td>77.299217</td>\n",
       "      <td>113.208954</td>\n",
       "      <td>148.616605</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.649112</td>\n",
       "      <td>34.464703</td>\n",
       "      <td>84.537522</td>\n",
       "      <td>60.543012</td>\n",
       "      <td>44.644150</td>\n",
       "      <td>151.042385</td>\n",
       "      <td>84.539253</td>\n",
       "      <td>83.959163</td>\n",
       "      <td>109.443827</td>\n",
       "      <td>153.688769</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>87.062305</td>\n",
       "      <td>42.953084</td>\n",
       "      <td>102.248729</td>\n",
       "      <td>74.060646</td>\n",
       "      <td>44.544899</td>\n",
       "      <td>150.612683</td>\n",
       "      <td>102.271828</td>\n",
       "      <td>101.646390</td>\n",
       "      <td>106.728786</td>\n",
       "      <td>157.587712</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>80.722945</td>\n",
       "      <td>30.541489</td>\n",
       "      <td>97.172116</td>\n",
       "      <td>67.565005</td>\n",
       "      <td>43.635659</td>\n",
       "      <td>174.571890</td>\n",
       "      <td>97.180150</td>\n",
       "      <td>95.961302</td>\n",
       "      <td>105.377963</td>\n",
       "      <td>161.036018</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>58.633316</td>\n",
       "      <td>41.822711</td>\n",
       "      <td>65.282357</td>\n",
       "      <td>52.016893</td>\n",
       "      <td>47.702329</td>\n",
       "      <td>94.790345</td>\n",
       "      <td>65.282910</td>\n",
       "      <td>65.775035</td>\n",
       "      <td>117.519573</td>\n",
       "      <td>140.586797</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>76.629676</td>\n",
       "      <td>43.004951</td>\n",
       "      <td>86.135709</td>\n",
       "      <td>70.765679</td>\n",
       "      <td>40.971657</td>\n",
       "      <td>131.501800</td>\n",
       "      <td>86.165952</td>\n",
       "      <td>87.282129</td>\n",
       "      <td>113.946320</td>\n",
       "      <td>150.938193</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>77.544773</td>\n",
       "      <td>35.287250</td>\n",
       "      <td>91.835958</td>\n",
       "      <td>65.596505</td>\n",
       "      <td>44.165027</td>\n",
       "      <td>158.776908</td>\n",
       "      <td>91.843084</td>\n",
       "      <td>91.134910</td>\n",
       "      <td>107.729195</td>\n",
       "      <td>156.696574</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>836 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gry          b           g          r          h           s  \\\n",
       "0    80.279621  34.183760   94.398857  70.153900  42.267678  165.889913   \n",
       "1    77.393634  39.465580   89.203236  68.729331  42.560133  143.786610   \n",
       "2    82.039218  39.302562   95.349459  72.226219  42.612996  151.611681   \n",
       "3    67.438145  38.150518   77.346432  59.177782  44.345727  129.958599   \n",
       "4    71.649112  34.464703   84.537522  60.543012  44.644150  151.042385   \n",
       "..         ...        ...         ...        ...        ...         ...   \n",
       "831  87.062305  42.953084  102.248729  74.060646  44.544899  150.612683   \n",
       "832  80.722945  30.541489   97.172116  67.565005  43.635659  174.571890   \n",
       "833  58.633316  41.822711   65.282357  52.016893  47.702329   94.790345   \n",
       "834  76.629676  43.004951   86.135709  70.765679  40.971657  131.501800   \n",
       "835  77.544773  35.287250   91.835958  65.596505  44.165027  158.776908   \n",
       "\n",
       "              v           l           a          bl  ...  orb_v11  orb_v12  \\\n",
       "0     94.401796   94.009250  108.220617  158.627226  ...     12.0     12.0   \n",
       "1     89.224835   89.600067  110.960220  153.843064  ...      7.0     13.0   \n",
       "2     95.349459   95.417023  109.145027  156.659661  ...     24.0     14.0   \n",
       "3     77.348153   77.299217  113.208954  148.616605  ...     17.0     37.0   \n",
       "4     84.539253   83.959163  109.443827  153.688769  ...     10.0     16.0   \n",
       "..          ...         ...         ...         ...  ...      ...      ...   \n",
       "831  102.271828  101.646390  106.728786  157.587712  ...     24.0     23.0   \n",
       "832   97.180150   95.961302  105.377963  161.036018  ...     54.0      6.0   \n",
       "833   65.282910   65.775035  117.519573  140.586797  ...     14.0     23.0   \n",
       "834   86.165952   87.282129  113.946320  150.938193  ...      2.0     27.0   \n",
       "835   91.843084   91.134910  107.729195  156.696574  ...     14.0      7.0   \n",
       "\n",
       "     orb_v13  orb_v14  orb_v15  orb_v16  orb_v17  orb_v18  orb_v19  orb_v20  \n",
       "0       19.0     24.0     10.0      3.0     35.0     19.0     14.0     24.0  \n",
       "1       10.0     57.0     28.0      3.0      6.0     10.0     12.0     19.0  \n",
       "2       35.0     25.0     11.0     11.0     46.0     10.0     30.0     12.0  \n",
       "3       17.0     42.0     21.0     12.0     12.0     10.0      8.0     12.0  \n",
       "4       12.0     33.0     15.0      2.0     10.0     14.0     21.0     23.0  \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...  \n",
       "831     24.0     11.0      7.0     52.0      9.0     14.0     17.0     20.0  \n",
       "832     32.0     17.0      6.0     22.0     20.0     37.0      4.0     15.0  \n",
       "833      9.0     40.0     15.0     11.0      7.0     12.0     37.0     31.0  \n",
       "834     21.0     42.0     20.0      3.0     26.0     12.0     19.0     33.0  \n",
       "835     22.0     12.0      9.0     29.0      5.0     24.0      3.0     11.0  \n",
       "\n",
       "[836 rows x 230 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
